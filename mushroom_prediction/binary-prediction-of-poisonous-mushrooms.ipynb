{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Goal\nuncover patterns in the data and use them to build a model to identify which mushrooms are edible or poisonous\n\nfollowed this notebook: https://www.kaggle.com/code/annastasy/ps4e8-data-cleaning-and-eda-of-mushrooms#-1.-Importing-Required-Libraries-","metadata":{}},{"cell_type":"markdown","source":"### Import libraries and Dataset","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np \nfrom scipy import stats\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import mosaic\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.ensemble import IsolationForest\n\npalette = sns.color_palette(\"Spectral\", n_colors=13) \nsns.set_theme(context='notebook', palette=palette, style='darkgrid')\nrs = 101","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-22T18:56:41.103371Z","iopub.execute_input":"2024-08-22T18:56:41.103945Z","iopub.status.idle":"2024-08-22T18:56:41.124386Z","shell.execute_reply.started":"2024-08-22T18:56:41.103899Z","shell.execute_reply":"2024-08-22T18:56:41.123017Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv')\ndf_sub = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:56:41.126415Z","iopub.execute_input":"2024-08-22T18:56:41.127283Z","iopub.status.idle":"2024-08-22T18:56:59.499280Z","shell.execute_reply.started":"2024-08-22T18:56:41.127245Z","shell.execute_reply":"2024-08-22T18:56:59.498106Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Explore on data","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:56:59.500643Z","iopub.execute_input":"2024-08-22T18:56:59.500949Z","iopub.status.idle":"2024-08-22T18:56:59.528713Z","shell.execute_reply.started":"2024-08-22T18:56:59.500922Z","shell.execute_reply":"2024-08-22T18:56:59.527506Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   id class  cap-diameter cap-shape cap-surface cap-color  \\\n0   0     e          8.80         f           s         u   \n1   1     p          4.51         x           h         o   \n2   2     e          6.94         f           s         b   \n3   3     e          3.88         f           y         g   \n4   4     e          5.85         x           l         w   \n\n  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n0                    f               a            c          w  ...   \n1                    f               a            c          n  ...   \n2                    f               x            c          w  ...   \n3                    f               s          NaN          g  ...   \n4                    f               d          NaN          w  ...   \n\n   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n0        NaN           NaN          w       NaN        NaN        f         f   \n1        NaN             y          o       NaN        NaN        t         z   \n2        NaN             s          n       NaN        NaN        f         f   \n3        NaN           NaN          w       NaN        NaN        f         f   \n4        NaN           NaN          w       NaN        NaN        f         f   \n\n  spore-print-color habitat season  \n0               NaN       d      a  \n1               NaN       d      w  \n2               NaN       l      w  \n3               NaN       d      u  \n4               NaN       g      a  \n\n[5 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>cap-diameter</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>does-bruise-or-bleed</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-color</th>\n      <th>...</th>\n      <th>stem-root</th>\n      <th>stem-surface</th>\n      <th>stem-color</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>has-ring</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>e</td>\n      <td>8.80</td>\n      <td>f</td>\n      <td>s</td>\n      <td>u</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>p</td>\n      <td>4.51</td>\n      <td>x</td>\n      <td>h</td>\n      <td>o</td>\n      <td>f</td>\n      <td>a</td>\n      <td>c</td>\n      <td>n</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>o</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>t</td>\n      <td>z</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>e</td>\n      <td>6.94</td>\n      <td>f</td>\n      <td>s</td>\n      <td>b</td>\n      <td>f</td>\n      <td>x</td>\n      <td>c</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>s</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>l</td>\n      <td>w</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>e</td>\n      <td>3.88</td>\n      <td>f</td>\n      <td>y</td>\n      <td>g</td>\n      <td>f</td>\n      <td>s</td>\n      <td>NaN</td>\n      <td>g</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>e</td>\n      <td>5.85</td>\n      <td>x</td>\n      <td>l</td>\n      <td>w</td>\n      <td>f</td>\n      <td>d</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>g</td>\n      <td>a</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:56:59.531284Z","iopub.execute_input":"2024-08-22T18:56:59.531656Z","iopub.status.idle":"2024-08-22T18:56:59.570856Z","shell.execute_reply.started":"2024-08-22T18:56:59.531624Z","shell.execute_reply":"2024-08-22T18:56:59.569712Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"        id  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n0  3116945          8.64         x         NaN         n                    t   \n1  3116946          6.90         o           t         o                    f   \n2  3116947          2.00         b           g         n                    f   \n3  3116948          3.47         x           t         n                    f   \n4  3116949          6.17         x           h         y                    f   \n\n  gill-attachment gill-spacing gill-color  stem-height  ...  stem-root  \\\n0             NaN          NaN          w        11.13  ...          b   \n1             NaN            c          y         1.27  ...        NaN   \n2             NaN            c          n         6.18  ...        NaN   \n3               s            c          n         4.98  ...        NaN   \n4               p          NaN          y         6.73  ...        NaN   \n\n  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n0          NaN          w         u          w        t         g   \n1          NaN          n       NaN        NaN        f         f   \n2          NaN          n       NaN        NaN        f         f   \n3          NaN          w       NaN          n        t         z   \n4          NaN          y       NaN          y        t       NaN   \n\n  spore-print-color habitat season  \n0               NaN       d      a  \n1               NaN       d      a  \n2               NaN       d      s  \n3               NaN       d      u  \n4               NaN       d      u  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cap-diameter</th>\n      <th>cap-shape</th>\n      <th>cap-surface</th>\n      <th>cap-color</th>\n      <th>does-bruise-or-bleed</th>\n      <th>gill-attachment</th>\n      <th>gill-spacing</th>\n      <th>gill-color</th>\n      <th>stem-height</th>\n      <th>...</th>\n      <th>stem-root</th>\n      <th>stem-surface</th>\n      <th>stem-color</th>\n      <th>veil-type</th>\n      <th>veil-color</th>\n      <th>has-ring</th>\n      <th>ring-type</th>\n      <th>spore-print-color</th>\n      <th>habitat</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3116945</td>\n      <td>8.64</td>\n      <td>x</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>t</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>11.13</td>\n      <td>...</td>\n      <td>b</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>u</td>\n      <td>w</td>\n      <td>t</td>\n      <td>g</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3116946</td>\n      <td>6.90</td>\n      <td>o</td>\n      <td>t</td>\n      <td>o</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>c</td>\n      <td>y</td>\n      <td>1.27</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3116947</td>\n      <td>2.00</td>\n      <td>b</td>\n      <td>g</td>\n      <td>n</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>c</td>\n      <td>n</td>\n      <td>6.18</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>f</td>\n      <td>f</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3116948</td>\n      <td>3.47</td>\n      <td>x</td>\n      <td>t</td>\n      <td>n</td>\n      <td>f</td>\n      <td>s</td>\n      <td>c</td>\n      <td>n</td>\n      <td>4.98</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>w</td>\n      <td>NaN</td>\n      <td>n</td>\n      <td>t</td>\n      <td>z</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3116949</td>\n      <td>6.17</td>\n      <td>x</td>\n      <td>h</td>\n      <td>y</td>\n      <td>f</td>\n      <td>p</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>6.73</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>NaN</td>\n      <td>y</td>\n      <td>t</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>d</td>\n      <td>u</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"there are {df_train.shape[1]} colums and {df_train.shape[0]} rows in train_df\")\nprint(f\"there are {df_test.shape[1]} colums and {df_test.shape[0]} rows in test_df\")","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:56:59.572080Z","iopub.execute_input":"2024-08-22T18:56:59.572484Z","iopub.status.idle":"2024-08-22T18:56:59.586153Z","shell.execute_reply.started":"2024-08-22T18:56:59.572450Z","shell.execute_reply":"2024-08-22T18:56:59.584846Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"there are 22 colums and 3116945 rows in train_df\nthere are 21 colums and 2077964 rows in test_df\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Colum names and data type of each column\")\ndf_train.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:56:59.587996Z","iopub.execute_input":"2024-08-22T18:56:59.589114Z","iopub.status.idle":"2024-08-22T18:56:59.605286Z","shell.execute_reply.started":"2024-08-22T18:56:59.589065Z","shell.execute_reply":"2024-08-22T18:56:59.604124Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Colum names and data type of each column\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"id                        int64\nclass                    object\ncap-diameter            float64\ncap-shape                object\ncap-surface              object\ncap-color                object\ndoes-bruise-or-bleed     object\ngill-attachment          object\ngill-spacing             object\ngill-color               object\nstem-height             float64\nstem-width              float64\nstem-root                object\nstem-surface             object\nstem-color               object\nveil-type                object\nveil-color               object\nhas-ring                 object\nring-type                object\nspore-print-color        object\nhabitat                  object\nseason                   object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#check is there any duplicates in df_train\nprint(\"There are {} duplicates in train dataset\".format(df_train.duplicated().sum()))","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:56:59.606810Z","iopub.execute_input":"2024-08-22T18:56:59.607252Z","iopub.status.idle":"2024-08-22T18:57:08.130943Z","shell.execute_reply.started":"2024-08-22T18:56:59.607218Z","shell.execute_reply":"2024-08-22T18:57:08.129760Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"There are 0 duplicates in train dataset\n","output_type":"stream"}]},{"cell_type":"code","source":"#Checking missing values in df_train\nprint(\"Checking missing values\")\nprint(df_train.isnull().mean() * 100)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:57:08.132191Z","iopub.execute_input":"2024-08-22T18:57:08.132514Z","iopub.status.idle":"2024-08-22T18:57:13.145432Z","shell.execute_reply.started":"2024-08-22T18:57:08.132487Z","shell.execute_reply":"2024-08-22T18:57:13.144339Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Checking missing values\nid                       0.000000\nclass                    0.000000\ncap-diameter             0.000128\ncap-shape                0.001283\ncap-surface             21.528227\ncap-color                0.000385\ndoes-bruise-or-bleed     0.000257\ngill-attachment         16.809280\ngill-spacing            40.373988\ngill-color               0.001829\nstem-height              0.000000\nstem-width               0.000000\nstem-root               88.452732\nstem-surface            63.551362\nstem-color               0.001219\nveil-type               94.884350\nveil-color              87.936970\nhas-ring                 0.000770\nring-type                4.134818\nspore-print-color       91.425482\nhabitat                  0.001444\nseason                   0.000000\ndtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Data cleansing\n\nColumns which have missing data\n* spore-print-color       91.425482\n* veil-type               94.884350\n* veil-color              87.936970\n* stem-root               88.452732\n* stem-surface            63.551362\n* gill-spacing            40.373988","metadata":{}},{"cell_type":"code","source":"#drop column name 'id' which will not going to be used for prediciton\n\ndf_train = df_train.drop(columns=['id'])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:57:13.146751Z","iopub.execute_input":"2024-08-22T18:57:13.147080Z","iopub.status.idle":"2024-08-22T18:57:13.826713Z","shell.execute_reply.started":"2024-08-22T18:57:13.147051Z","shell.execute_reply":"2024-08-22T18:57:13.825539Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"df_train_cleaned = df_train.copy()\ndf_test_cleaned = df_test.copy()\n\n#set up target column\ntarget_column = 'class'\n\n#select categorial columns\ncategorical_columns = df_train_cleaned.select_dtypes(include=[object]).columns\ncategorical_columns = categorical_columns.drop(target_column)\n\n#select numerical cloumns\nnumerical_columns = df_train_cleaned.select_dtypes(exclude=[object]).columns\n\n#print out lists of columns\nprint(\"target column:\", target_column)\nprint(\"\\n categorical columns:\", categorical_columns)\nprint(\"\\n numerical columns:\", numerical_columns)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:57:13.829823Z","iopub.execute_input":"2024-08-22T18:57:13.830195Z","iopub.status.idle":"2024-08-22T18:57:15.504740Z","shell.execute_reply.started":"2024-08-22T18:57:13.830164Z","shell.execute_reply":"2024-08-22T18:57:15.503324Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"target column: class\n\n categorical columns: Index(['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed',\n       'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root',\n       'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring',\n       'ring-type', 'spore-print-color', 'habitat', 'season'],\n      dtype='object')\n\n numerical columns: Index(['cap-diameter', 'stem-height', 'stem-width'], dtype='object')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Deal with Infrequent Categories","metadata":{}},{"cell_type":"code","source":"#categorial columns\nfor column in categorical_columns:\n    num_unique = df_train_cleaned[column].nunique()\n    print(f\"'{column}' has {num_unique} unique categories.\")\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-22T18:57:15.506126Z","iopub.execute_input":"2024-08-22T18:57:15.506442Z","iopub.status.idle":"2024-08-22T18:57:18.144296Z","shell.execute_reply.started":"2024-08-22T18:57:15.506414Z","shell.execute_reply":"2024-08-22T18:57:18.143081Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"'cap-shape' has 74 unique categories.\n'cap-surface' has 83 unique categories.\n'cap-color' has 78 unique categories.\n'does-bruise-or-bleed' has 26 unique categories.\n'gill-attachment' has 78 unique categories.\n'gill-spacing' has 48 unique categories.\n'gill-color' has 63 unique categories.\n'stem-root' has 38 unique categories.\n'stem-surface' has 60 unique categories.\n'stem-color' has 59 unique categories.\n'veil-type' has 22 unique categories.\n'veil-color' has 24 unique categories.\n'has-ring' has 23 unique categories.\n'ring-type' has 40 unique categories.\n'spore-print-color' has 32 unique categories.\n'habitat' has 52 unique categories.\n'season' has 4 unique categories.\n","output_type":"stream"}]},{"cell_type":"code","source":"#print top 10 unique value counts for each categorical column\nfor column in categorical_columns:\n    print(f\"\\n top value counts in '{column}' : \\n {df_train_cleaned[column].value_counts().head(10)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"some categories don't show up often compared to other categories <p>\nto fix this group these rate categories together into a new category called \"Unknown\" <p>\nThreshold is 70","metadata":{}},{"cell_type":"code","source":"def replace_infrequent_categories(df, column, threshold=70):\n    value_counts = df[column].value_counts()\n    infrequent = value_counts[value_counts <= threshold].index\n    df[column] = df[column].apply(lambda x: \"unknown\" if x in infrequent else x)\n    return df\n\n#handle infrequent categories in both train and test dataset\n\nfor col in categorical_columns:\n    df_train_cleaned = replace_infrequent_categories(df_train_cleaned, col)\n    df_test_cleaned = replace_infrequent_categories(df_test_cleaned, col)\n    \n#print out cleaned results in both train and test dataset\nprint(\"replacement results\")\nfor column in categorical_columns:\n    num_unique = df_train_cleaned[column].nunique()\n    print(f\"'{column}' has {num_unique} categories.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill Missing values in Numerical columns\n\n1. check skewness of data <p>\n   what is skewness: 데이터 분포의 비대칭성 측정\n   * the more skew value is closer to 0, this means dataset distributed as symmetrically <p>\n    \n2. use meadian value to fill NA values: as skewness of all numerical columns is more than 1, so used the median value to fill in any missing values","metadata":{}},{"cell_type":"code","source":"#check skewness of data\n\nprint(\"The skewness of columns:\")\nprint(df_train_cleaned[numerical_columns].skew())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"medians = df_train_cleaned[numerical_columns].median()\n\n#Fill missing values in the training and testing sets\ndf_train_cleaned[numerical_columns] = df_train_cleaned[numerical_columns].fillna(medians)\ndf_test_cleaned[numerical_columns] = df_test_cleaned[numerical_columns].fillna(medians)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fill Missing values in categorical columns","metadata":{}},{"cell_type":"code","source":"# Impute any missing values with 'Unknown'\ndf_train_cleaned = df_train_cleaned.fillna(\"Unknown\")\ndf_test_cleaned = df_test_cleaned.fillna(\"Unknown\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check duplicates and clean them \n\nprint(\"There are {} duplicates in train dataset.\".format(df_train_cleaned.duplicated().sum()))\nprint(\"There are {} duplicates in test dataset.\".format(df_test_cleaned.duplicated().sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_cleaned = df_train_cleaned.drop_duplicates()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis(EDA)\n\n1. distribution of numerical features\n2. distribution of categorical features\n3. correlation in numerical features\n4. correlation in categorical features\n5. exploring outliers\n6. distribution of a target variable","metadata":{}},{"cell_type":"markdown","source":"### Distribution of numerical Features","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,15))\n\nfor i, column in enumerate(numerical_columns):\n    plt.subplot(3, 1, i+1)\n    #draw histogram x axis: column , kde = 히스토그램 위에 밀도 곡선 추가?, bis = 히스토그램에서 사용할 구각의 개수 지정\n    sns.histplot(data=df_train_cleaned, x=column, kde=True, bins=20) \n    \n    plt.title(f'Distribution of {column}')\n    \n    #플롯의 축 선(spine) 제거하거나 간소화\n    sns.despine()\n    \n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution of numerical columns is right-skewed with outliers <p>\nthis means there are some unusually high values(outliers) that are far away from the rest. \n<p>\nThis suggest data is may not be normally distriuted, which could impact our analysis and modeling results.\n","metadata":{}},{"cell_type":"markdown","source":"### Distribution of Categorical Features","metadata":{}},{"cell_type":"code","source":"#plot countplots for each categorical column\nfor column in categorical_columns:\n    #exclude 'unknown'\n    filtered_data = df_train_cleaned.loc[df_train_cleaned[column] != 'Unknown']\n    \n    #draw figure\n    plt.figure(figsize=(8,5))\n    sns.countplot(data=filtered_data, x=column)\n    plt.title(f'Countplot of {column}')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploring Correlations betweeb Numerical Features","metadata":{}},{"cell_type":"code","source":"custom_palette = sns.color_palette([\"#5b81d4\", \"#b03e4d\"])\n\npairplot = sns.pairplot(df_train_cleaned, hue='class', palette=custom_palette)\npairplot.figure.suptitle('Pairplot', fontsize=22, y=1.02)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to pairplot, poisonous mushrooms tend to have smaller ecaps and narrower stems","metadata":{}},{"cell_type":"code","source":"for column in numerical_columns:\n    plt.figure(figsize=(8,6))\n    sns.violinplot(data=df_train_cleaned, x='class', y=column)\n    plt.title(f'Distribution of {column} by class')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This plot shows there are presence of outliers","metadata":{}},{"cell_type":"markdown","source":"### Exploring Correlations between categorical Features","metadata":{}},{"cell_type":"code","source":"#plot mosaic plots for each categorical column, excluding \"Unknown\" values\nfor column in categorical_columns:\n    filtered_data = df_train_cleaned.loc[df_train_cleaned[column] != 'Unknown']\n    \n    plt.figure(figsize=(8,6))\n    mosaic(filtered_data, [column,'class'])\n    plt.title(f'Mosaic Plot of {column} and class')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on visualization above, ti is evident that edible and poisonous mushrroms have distinct chatacteristics. <p>\n    \nFor example,<p>\nEdible mushrooms\n* more prevalent in summer and winter <p>\n\nPoisonous mushrooms\n* more prevalent in autumn and spring\n","metadata":{}},{"cell_type":"markdown","source":"### Exploring Outliers\n\nuse z score to explore outliers\n* z score는 데이터를 표준 정규 분포로 변환하여 평균을 0 표준 편차를 1로 만듬 -> 데이터의 원래 단위나 척도와 관계없이 일관된 비교가 가능해짐\n* z score는 데이터 포인트가 평균에서 얼마나 떨어져 있는지를 표준 편차 단위로 나타냄 -> z score가 +-3을 넘는 데이터 포인트는 평균에서 많이 벗어난 것으로 간주되어 이상치로 식별됨\n* z score를 사용하면 데이터가 특정 범위 내에 얼마나 몰려 있는지, 어떤 값들이 극단적으로 높은지 또는 낮은지 파악할 수 있음","metadata":{}},{"cell_type":"code","source":"#Calculate Z scores for the mumerical columns in the dataframe\n\nz_scores = stats.zscore(df_train_cleaned[numerical_columns])\n\n#Generate descriptive statistics for the z-scores and round the results to 3 decimal places\nz_scores.describe().round(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the z score\n* outliers in 3 numerical columns: cap-diameter, stem-height, stem-width\n* Choose isolation forest for removing outliers\n","metadata":{}},{"cell_type":"markdown","source":"### Distribution of a Target Variable","metadata":{}},{"cell_type":"code","source":"#Calculate counts for the pie chart and add labels\n\nclass_counts = df_train_cleaned['class'].value_counts().sort_index()\nlabels = [\"Edible\",\"Poisonous\"]\n\nplt.figure(figsize=(6,6))\nplt.pie(class_counts, labels=labels, colors=custom_palette, autopct='%1.1f%%', startangle=90)\nplt.title('Distribution of classes')\nplt.axis('equal')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine Learning\n\nPreprocecssing steps\n1. Label Encoder initialization: start by creating an instance of `LabelEncoder`, which is used to convert categorical labels('edible', 'poisonous') into numerical values(like 0,1)\n2. Convert Categorical Columns to 'Category' dtype: this is efficient for memory usage and makes it easier to apply specific transformations to these columns\n3. Defining the Numerical Pipeline\n* Standard Scalar: this step standardizes the numerical features by removing the mean and scaling to unit variance\n* Convert to float 32: this step converts the data type to `float32` to save memory similar to converting categorical columns to category dtype\n4. Defining the Categorical pipeline: OrdinalEncoder: Encodes categorical feature as integers\n* `handle_unknown=use_encoded_value` allows handling of unseen categories during transformation by assigning them a specific value(such as -1)\n5. ColumnTransformer: combines the numerical and categorical pipeline into a single transformation step\n6. Apply transformations: \n* `fit_transformation` fits the preprocessor on the training data and applies the transformations. \n* `transform` applies the same transformations to the test data.\nNote that fit is not called onn the test data to avoid data leakage","metadata":{}},{"cell_type":"code","source":"#Initialize Encoder\nlabel_encoder = LabelEncoder()\n\n#Fit and transform the target variable\ntrain_encoded_target = label_encoder.fit_transform(df_train_cleaned[['class']])\n\n#convert categorical columns to 'category' dtype\ndf_train_cleaned[categorical_columns] = df_train_cleaned[categorical_columns].astype('category')\ndf_test_cleaned[categorical_columns] = df_test_cleaned[categorical_columns].astype('category')\n\n#define numerical pipeline\nnumerical_pipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('convert_to_float32', FunctionTransformer(lambda x: x.astype(np.float32)))\n])\n\n#Define categorical pipeline\ncategorical_pipeline = Pipeline(steps=[\n     ('ordinal', OrdinalEncoder(dtype=np.int32, handle_unknown='use_encoded_value', unknown_value=-1))\n])\n\n#Combine both numerical and categorical pipelines\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_pipeline, numerical_columns),\n        ('cat', categorical_pipeline, categorical_columns)\n    ]\n)\n\n# Apply the transformations using the pipeline\ndf_train_preprocessed = preprocessor.fit_transform(df_train_cleaned)\ndf_test_preprocessed = preprocessor.transform(df_test_cleaned)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Difference between fit_transform and transform***\n\n* fit_transform: fit()데이터를 기반으로 필요한 통계값을 계산하여 모델을 학습 -> 학습한 모델을 사용하여 데이터를 변환(보통 training 데이터에 많이 사용)\n* transform: 이미 학습된 모델을 사용하여 데이터를 변환 (보통 테스트 데이터에 많이 사용)","metadata":{}},{"cell_type":"markdown","source":"**Isolation forest**\n\n1. randomly sampling data and make many subsets\n2. random으로 데이터 분할 -> build isolation tree\n3. 데이터를 계속해서 분할하면서 특정 데이터 포인트가 얼마나 빨리 분리되는지 확인 -> 빨리 분리될수록 이상치일 확률 높음\n4. 각 데이터 포인트에서 여러 트리에서 평균적으로 고립되는 수준을 계산(길이가 짧을수록 이상치일 가능성이 높음)","metadata":{}},{"cell_type":"code","source":"# Apply Isolation Forest for outlier detection\nisolation_forest = IsolationForest(contamination=0.02, random_state=rs)\noutlier_labels = isolation_forest.fit_predict(df_train_preprocessed)\n\n# Filter out outliers\nnon_outliers_mask = outlier_labels != -1\ndf_train_preprocessed = df_train_preprocessed[non_outliers_mask]\ntrain_encoded_target = train_encoded_target[non_outliers_mask]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Separate features (X) and target variable (y)\nX = df_train_preprocessed\ny = train_encoded_target\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**XGBClassifier**\n\n* Gradient Boosting algorithm: 여러개의 약한 학습기를(대부분 결정트리) 결합하여 강력한 모델 생성, 새로운 학습기는 이전 학습기의 오차를 줄이기 위해 학습\n* Regularization: L1, L2 정규화를 지원하여 과적합 방지\n* Can automatically handle missing values\n* Support parellelization\n* tree pruning, max_depth\n* Cross validation\n* Suitable for large dataset","metadata":{}},{"cell_type":"code","source":"## Tuning Hyperparameters\n\n# Define the XGBClassifier\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n\n# Define the parameter grid\nparam_grid = {\n    'n_estimators': [100, 200, 500],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'max_depth': [1, 5, 7, 14],\n    'min_child_weight': [1, 5, 10],\n    'subsample': [0.5, 0.9],\n    'colsample_bytree': [0.4, 0.6, 0.8]\n}\n\n# Define a custom scoring function for MCC\ndef mcc_scorer(estimator, X, y):\n    y_pred = estimator.predict(X)\n    return matthews_corrcoef(y, y_pred)\n\n# Setup the GridSearchCV\ngrid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, \n                           scoring=mcc_scorer, \n                           cv=5, \n                           verbose=1, \n                           n_jobs=-1)\n\n# Fit GridSearchCV\ngrid_search.fit(X_train, y_train)\n\n# Print the best parameters and best score\nprint(\"Best Parameters:\\n\", grid_search.best_params_)\nprint(\"Best MCC Score:\\n\", grid_search.best_score_)\n\n# Predict on the test set\ny_pred = grid_search.best_estimator_.predict(X_test)\n\n# Evaluate the model\nprint(\"Test MCC Score:\", matthews_corrcoef(y_test, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the best parameters\nparams = {\n    'colsample_bytree': 0.4, \n    'learning_rate': 0.1, \n    'max_depth': 14, \n    'min_child_weight': 1, \n    'n_estimators': 200, \n    'subsample': 0.9,\n    'use_label_encoder': False,  \n    'eval_metric': 'mlogloss'   \n}\n\n# Initialize the XGBClassifier with the defined parameters\nxgb_model = XGBClassifier(**params)\n\n# Fit the model to the training data \nxgb_model.fit(X_train, y_train)\n\n# Predict on the test data \ny_pred = xgb_model.predict(X_test)\n\n# Evaluate the model using Matthews correlation coefficient\nmcc = matthews_corrcoef(y_test, y_pred)\nprint(\"Matthews Correlation Coefficient:\", mcc)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions and Submission","metadata":{}},{"cell_type":"code","source":"test_preds = xgb_model.predict(df_test_preprocessed)\ntest_preds = label_encoder.inverse_transform(test_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': df_test['id'],\n                       'class': test_preds})\n\noutput.to_csv('submission.csv', index=False)\n\noutput.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}